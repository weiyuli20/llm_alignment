{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08d9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ExpertNetWork(nn.Module):\n",
    "    '''升维降维操作'''\n",
    "    def __init__(self,hidden_size, intermediate_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "\n",
    "        self.linear1 = nn.Linear(hidden_size,intermediate_size)\n",
    "        self.linear2 = nn.Linear(intermediate_size,hidden_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        output = self.linear2(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6cef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(nn.Module):\n",
    "    def __init__(self, hidden_size,expert_num,top_k):\n",
    "        super().__init__()\n",
    "        self.router = nn.Linear(hidden_size,expert_num)\n",
    "        self.top_k = top_k\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,self.hidden_size)\n",
    "        x = self.router(x)  #每一个token 过router层\n",
    "        x = nn.functional.softmax(x,dim = -1)\n",
    "        topk_weight, topk_idx = torch.topk(x,k =self.top_k,dim = -1,sorted=False)\n",
    "        #对topk权重进行归一化\n",
    "        topk_weight = topk_weight / topk_weight.sum(dim = -1, keepdim=True)\n",
    "        return topk_weight,topk_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11, 4096])\n"
     ]
    }
   ],
   "source": [
    "class MOELayer(nn.Module):\n",
    "    def __init__(self, hidden_size, intermediate_size,expert_num,top_k):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.expert_num = expert_num\n",
    "        self.top_k = top_k\n",
    "        self.experts = nn.ModuleList([ExpertNetWork(self.hidden_size,self.intermediate_size) for _ in range(self.expert_num)])\n",
    "        self.router = Router(self.hidden_size,self.expert_num,self.top_k)\n",
    "\n",
    "    def forward(self,x):\n",
    "        batch_size,seq_len,_ = x.size()\n",
    "        token_num = batch_size * seq_len\n",
    "        x_flat = x.view(token_num,self.hidden_size) #对每个token独立计算\n",
    "        topk_weight,topk_idx = self.router(x_flat) #(N,K)\n",
    "        #初始化输出张量\n",
    "        output = torch.zeros_like(x_flat)\n",
    "        for token_idx in range(token_num):\n",
    "            for expert_idx in range(self.top_k):\n",
    "                expert = self.experts[topk_idx[token_idx,expert_idx]]\n",
    "                output[token_idx]+= topk_weight[token_idx,expert_idx] * expert(x_flat[token_idx])\n",
    "        output = output.view(batch_size,seq_len,self.hidden_size)\n",
    "        return output\n",
    "    \n",
    "hidden_size = 4096\n",
    "intermediate_size = 2048\n",
    "expert_num = 8\n",
    "top_k = 2\n",
    "\n",
    "inputs = torch.randn((2,11,4096))\n",
    "moe_layer  =MOELayer(hidden_size,intermediate_size,expert_num,top_k)\n",
    "outputs = moe_layer(inputs)\n",
    "print(outputs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
